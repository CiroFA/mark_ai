currently face, and will continue to face claims and government and regulatory inquiries relating to information or content that is published or made available on our products, including claims, inquiries, and investigations relating to our policies, algorithms, and enforcement decisions with respect to such information or content. In particular, the nature of our business exposes us to claims related to defamation, dissemination of misinformation or news hoaxes, deceptive and fraudulent advertising, discrimination, harassment, intellectual property rights, rights of publicity and privacy, personal injury torts, laws regulating hate speech or other types of content, on- or offline safety and well-being (such as acts of violence, terrorism, improper promotion or distribution of pharmaceuticals and illicit drugs, human exploitation, child exploitation, illegal gaming, and other fraudulent or otherwise illegal activity), products liability, consumer protection, and breach of contract, among others. For example, over the last several years we have seen an increase in claims brought by younger users related to well-being issues based on allegedly harmful content that is shared on or recommended by our products. In addition, we have been subject to litigation alleging that our ad targeting and delivery practices constitute violations of anti-discrimination laws.
The potential risks relating to any of the foregoing types of claims are currently enhanced in certain jurisdictions outside the United States where our protection from liability for third-party actions may be unclear or where we may be less
42
Table of
Contents
protected under local laws than we are in the United States. For example, in April 2019, the European Union passed a directive (the European Copyright Directive) expanding online platform liability for copyright infringement and regulating certain uses of news content online, which the EU member states have since implemented into their national laws. In addition, the European Union revised the European Audiovisual Media Service Directive to apply to online video-sharing platforms, which member states are implementing. Additionally, Brazil has an intermediary liability framework limiting liability for third-party content, which has been challenged as unconstitutional and is under review by the Brazilian Supreme Court. In the United States, in 2023, the U.S. Supreme Court heard oral argument in a matter in which the scope of the protections available to online platforms under Section 230 of the Communications Decency Act (Section 230) was at issue, but it ultimately declined to address Section 230 in its decision. There also have been, and continue to be, various other litigation concerning, and state and federal legislative and executive efforts to remove or restrict, the scope of the protections under SectionÂ 230, as well as to impose new obligations on online platforms with respect to commerce listings, user access and content,
or other value to justify our investments, and our business may be adversely affected.
We may not be successful in our artificial intelligence initiatives, which could adversely affect our business, reputation, or financial results.
We are making significant investments in AI initiatives, including generative AI, to, among other things, recommend relevant content across our products, enhance our advertising tools, develop new products, and develop new features for existing products. In particular, we expect our AI initiatives will require increased investment in infrastructure and headcount. If our investments are not successful longer-term, our business and financial performance could be harmed.
20
Table of
Contents
There are significant risks involved in developing and deploying AI and there can be no assurance that the usage of AI will enhance our products or services or be beneficial to our business, including our efficiency or profitability. For example, our AI-related efforts, particularly those related to generative AI, subject us to risks related to harmful or illegal content, accuracy, misinformation and deepfakes (including related to elections), bias, discrimination, toxicity, consumer protection, intellectual property infringement or misappropriation, defamation, data privacy, cybersecurity, and sanctions and export controls, among others. It is also uncertain how various laws related to online services, intermediary liability, and other issues will apply to content generated by AI. In addition, we are subject to the risks of new or enhanced governmental or regulatory scrutiny, litigation, or other legal liability, ethical concerns, negative consumer perceptions as to automation and AI, activities that threaten people's safety or well-being on- or offline, or other complications that could adversely affect our business, reputation, or financial results.
As a result of the complexity and rapid development of AI, it is also the subject of evolving review by various governmental and regulatory agencies in jurisdictions around the world, which are applying, or are considering applying, platform moderation, intellectual property, cybersecurity, export controls, and data protection laws to AI and/or are considering general legal frameworks on AI (such as the recently passed EU AI Act). We may not always be able to anticipate how courts and regulators will apply existing laws to AI, predict how new legal frameworks will develop to address AI, or otherwise respond to these frameworks as they are still rapidly evolving. We may also have to expend resources to adapt to new legal frameworks, and adjust our offerings in certain jurisdictions if the legal frameworks on AI are not consistent across jurisdictions.
Further, we face significant competition from other companies that are developing their own AI features and technologies. Other companies may develop AI features and technologies that are similar or superior to our technologies or are more